# SMS Spam Detection using Naive Bayes & Logistic Regression

import pandas as pd
import numpy as np
import re
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# ----------------------------------------------------
# 1. Load Dataset
# ----------------------------------------------------
df = pd.read_csv("spam.csv", encoding='latin-1')

# Columns usually: ['label','message']
df = df[['label', 'message']]

# ----------------------------------------------------
# 2. Data Preprocessing (Cleaning + Tokenization)
# ----------------------------------------------------

# Label Encoding: spam = 1, ham = 0
df['label'] = df['label'].map({'spam':1, 'ham':0})

# Text cleaning function
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)   # remove numbers & symbols
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df['message'] = df['message'].apply(clean_text)

# Convert text → Bag of Words (Tokenization)
cv = CountVectorizer()
X = cv.fit_transform(df['message'])

y = df['label']

# ----------------------------------------------------
# 3. Train-Test Split
# ----------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ----------------------------------------------------
# 4. Apply Classification Models
# ----------------------------------------------------

# Model 1: Naive Bayes
nb = MultinomialNB()
nb.fit(X_train, y_train)
nb_pred = nb.predict(X_test)

# Model 2: Logistic Regression
lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)

# ----------------------------------------------------
# 5. Evaluation of Both Models
# ----------------------------------------------------

def evaluate(y_true, y_pred, model_name):
    print(f"\n✅ {model_name} Results")
    print("Accuracy :", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred))
    print("Recall   :", recall_score(y_true, y_pred))
    print("F1 Score :", f1_score(y_true, y_pred))

evaluate(y_test, nb_pred, "Naive Bayes")
evaluate(y_test, lr_pred, "Logistic Regression")

# ----------------------------------------------------
# 6. Cross-Validation
# ----------------------------------------------------
print("\n✅ Cross-Validation Scores")

nb_cv = cross_val_score(nb, X, y, cv=5).mean()
lr_cv = cross_val_score(lr, X, y, cv=5).mean()

print("Naive Bayes CV Accuracy:", nb_cv)
print("Logistic Regression CV Accuracy:", lr_cv)

# ----------------------------------------------------
# 7. Hyperparameter Tuning (GridSearch)
# ----------------------------------------------------
params = {'alpha':[0.1, 0.5, 1.0, 2.0]}

grid = GridSearchCV(MultinomialNB(), params, cv=5)
grid.fit(X_train, y_train)

print("\n✅ Best Parameters from GridSearch:", grid.best_params_)
print("✅ Best Score:", grid.best_score_)
